{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/labasi/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORMAT CUSTOM IMAGE INPUT\n",
      "\n",
      "Creating train.tfrecords...\n",
      "train.tfrecords data: 0/2844\n",
      "Corrupted record...\n",
      "Corrupted record...\n",
      "Corrupted record...\n",
      "Corrupted record...\n",
      "Corrupted record...\n",
      "train.tfrecords data: 1000/2844\n",
      "Corrupted record...\n",
      "Corrupted record...\n",
      "train.tfrecords data: 2000/2844\n",
      "Corrupted record...\n",
      "Corrupted record...\n",
      "\n",
      "Creating val.tfrecords...\n",
      "val.tfrecords data: 0/158\n",
      "Corrupted record...\n",
      "\n",
      "Creating test.tfrecords...\n",
      "test.tfrecords data: 0/179\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "\n",
    "## ------------------------------------------------------------\n",
    "## FORMAT CUTOM IMAGE DATA SET\n",
    "## --source: \n",
    "## Daniel Persson,'How to load a custom dataset with tf.data [Tensorflow]',\n",
    "## https://www.youtube.com/watch?v=bqeUmLCgsVw\n",
    "## ------------------------------------------------------------\n",
    "## I use PIL instead of cv2\n",
    "## ------------------------------------------------------------\n",
    "\n",
    "print(\"FORMAT CUSTOM IMAGE INPUT\")\n",
    "label_ids_list = []\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def createDataRecord(outFileName, addrs, labels):\n",
    "    print(\"\")\n",
    "    print('Creating '+outFileName+'...')\n",
    "    writer = tf.python_io.TFRecordWriter(outFileName)\n",
    "    for i in range(len(addrs)):\n",
    "        if not i % 1000:\n",
    "            print(outFileName+' data: {}/{}'.format(i,len(addrs)))\n",
    "            sys.stdout.flush()\n",
    "        ff = '/Volumes/imvDrive/cfdb-django/media/glyph_img/'+addrs.iloc[i]    \n",
    "        filename = os.fsdecode('/Volumes/imvDrive/cfdb-django/media/glyph_img/'+addrs.iloc[i][0])\n",
    "        if Path(filename).is_file():\n",
    "            try:\n",
    "                ######\n",
    "                ## Pre-processing\n",
    "                ######\n",
    "                img = Image.open(filename).convert('L') #convert to grayscale\n",
    "                img = img.resize((331,331)) \n",
    "                label = labels.iloc[i][0]\n",
    "                ascii_label = int(''.join(str(ord(c)) for c in label))\n",
    "                label_ids_list.append([ascii_label, label, addrs.iloc[i]])\n",
    "                feature_img = {\n",
    "                    'glyph_img_raw': _bytes_feature(img.tobytes()),\n",
    "                    'label_raw': _int64_feature(ascii_label)\n",
    "                }\n",
    "\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=feature_img))\n",
    "                writer.write(example.SerializeToString())\n",
    "                \n",
    "            except Exception:\n",
    "                print(\"Corrupted record...\")\n",
    "                pass\n",
    "    writer.close()\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "train_addrs = pd.read_csv('/Volumes/IMVDRIVE/cfdb-django/media/train_batch.csv', usecols=['glyph'])\n",
    "train_labels = pd.read_csv('/Volumes/IMVDRIVE/cfdb-django/media/train_batch.csv', usecols=['sign'])\n",
    "val_addrs = pd.read_csv('/Volumes/IMVDRIVE/cfdb-django/media/validation_batch.csv', usecols=['glyph'])\n",
    "val_labels = pd.read_csv('/Volumes/IMVDRIVE/cfdb-django/media/validation_batch.csv', usecols=['sign'])\n",
    "test_addrs = pd.read_csv('/Volumes/IMVDRIVE/cfdb-django/media/testing_batch.csv', usecols=['glyph'])\n",
    "test_labels = pd.read_csv('/Volumes/IMVDRIVE/cfdb-django/media/testing_batch.csv', usecols=['sign'])\n",
    "\n",
    "train_num_examples = len(train_addrs)\n",
    "val_num_examples = len(val_addrs)\n",
    "test_num_examples = len(test_addrs)\n",
    "\n",
    "createDataRecord('train.tfrecords', train_addrs, train_labels)\n",
    "createDataRecord('val.tfrecords', val_addrs, val_labels)\n",
    "createDataRecord('test.tfrecords', test_addrs, test_labels)\n",
    "\n",
    "labels = ['ascii', 'sign_name', 'sign_img']\n",
    "label_ids_df = pd.DataFrame.from_records(label_ids_list, columns=labels)\n",
    "label_ids_df.to_csv('label_ids.csv')\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------------------\n",
    "## READ INPUT: version 1\n",
    "## --source: \n",
    "## Daniel Persson,'How to load a custom dataset with tf.data [Tensorflow]',\n",
    "## https://www.youtube.com/watch?v=bqeUmLCgsVw\n",
    "## ------------------------------\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "channels = 1\n",
    "batch_size = 5\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def parser(record):\n",
    "    keys_to_features = {\n",
    "        \"glyph_img_raw\": tf.FixedLenFeature([], tf.string),\n",
    "        \"label_raw\": tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    \n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "    image = tf.decode_raw(parsed[\"glyph_img_raw\"], tf.uint8)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, shape=[331, 331, channels])\n",
    "    label = tf.cast(parsed[\"label_raw\"], tf.int32)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def input_fn(filenames, train, batch_size=batch_size, buffer_size=2048):\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "    dataset = dataset.map(parser)\n",
    "    \n",
    "    if train:\n",
    "        dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "        num_repeat = None\n",
    "    else:\n",
    "        num_repeat = 1\n",
    "        \n",
    "    dataset = dataset.repeat(num_repeat)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    images_batch, labels_batch = iterator.get_next()\n",
    "    x = {'image': images_batch}\n",
    "    y = labels_batch\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def train_input_fn():\n",
    "    return input_fn(filenames=['/Volumes/IMVDRIVE/cfdb-django/train.tfrecords'], train=True)\n",
    "\n",
    "def val_input_fn():\n",
    "    return input_fn(filenames=[\"/Volumes/IMVDRIVE/cfdb-django/val.tfrecords\"], train=True)\n",
    "\n",
    "def test_input_fn():\n",
    "    return input_fn(filenames=[\"/Volumes/IMVDRIVE/cfdb-django/test.tfrecords\"], train=False)\n",
    "\n",
    "for i in range(5):\n",
    "    try:\n",
    "        features, labels = train_input_fn()\n",
    "        img, label = sess.run([features['image'], labels])\n",
    "    except Exception:\n",
    "        print(\"An exception...\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING...\n",
      "Training Epoch 1 --- Training Accuracy:   0.0%, Validation Accuracy:   0.0%,  Validation Loss: 1174846.875\n",
      "Training Epoch 2 --- Training Accuracy:   0.0%, Validation Accuracy:   0.0%,  Validation Loss: 4078801.000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'OutOfRangeError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-efdbc6e060c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mfd_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_train_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mbatch_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_counter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/labasi/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/labasi/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/labasi/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/labasi/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/labasi/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-efdbc6e060c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mepoch_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_counter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/Volumes/imvDrive/cfdb-django/labasi_cnn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ending...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OutOfRangeError' is not defined"
     ]
    }
   ],
   "source": [
    "## ------------------------------\n",
    "## VARIABLES\n",
    "## ------------------------------\n",
    "\n",
    "sess = tf.Session()\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, 331, 331, 1])\n",
    "l = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "y_true_cls = tf.argmax(labels, axis=0)\n",
    "\n",
    "## ------------------------------\n",
    "## CONVOLUTIONAL NEURAL NETWORK\n",
    "## Adapted from:\n",
    "## https://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/\n",
    "## https://www.tensorflow.org/tutorials/images/deep_cnn\n",
    "## ------------------------------\n",
    "\n",
    "filter_shape = 5\n",
    "batches_to_process = 15\n",
    "\n",
    "def conv_layer1_fn(x,num_input_channels, num_filters):\n",
    "    W1 = tf.Variable(tf.truncated_normal([filter_shape,filter_shape,num_input_channels,num_filters], dtype=tf.float32))     \n",
    "    B1 = tf.Variable(tf.truncated_normal([num_filters]))\n",
    "    conv1 = tf.nn.conv2d(x, W1, strides=[1, 1, 1, 1], padding=\"SAME\") #stides=[batch_stride x_stride y_stride depth_stride]\n",
    "    biased_conv1 = conv1+B1\n",
    "    relu_for_conv = tf.nn.relu(biased_conv1)\n",
    "    pool1 = tf.nn.max_pool(relu_for_conv, ksize=[1, 2, 2, 1], strides=[1,2,2,1], padding='SAME')\n",
    "    norm1 = tf.nn.local_response_normalization(pool1,depth_radius=5,bias=1,alpha=1,beta=0.5,name=None)\n",
    "    return norm1\n",
    "    \n",
    "def conv_layer2_fn(layer, num_input_channels, num_filters):\n",
    "    W2 = tf.Variable(tf.truncated_normal([filter_shape,filter_shape,num_input_channels,num_filters], stddev=0.05)) #https://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/\n",
    "    B2 = tf.Variable(tf.truncated_normal([num_filters]))\n",
    "    conv2 = tf.nn.conv2d(layer, W2, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    biased_conv2 = conv2+B2\n",
    "    relu_for_conv = tf.nn.relu(biased_conv2)\n",
    "    norm2 = tf.nn.local_response_normalization(relu_for_conv,depth_radius=5,bias=1,alpha=1,beta=0.5,name=None)\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 2, 2, 1], strides=[1,2,2,1], padding='SAME')\n",
    "    return pool2\n",
    "\n",
    "def flat_layer(layer):                  \n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer = tf.reshape(layer, [-1, num_features])\n",
    "    return layer \n",
    "\n",
    "def fc_relu(layer, use_relu, output_num, reshape):\n",
    "    layer_shape = layer.get_shape()\n",
    "    W3 = tf.Variable(tf.truncated_normal([layer_shape[1:4].num_elements(), output_num], stddev=0.05))\n",
    "    B3 = tf.Variable(tf.truncated_normal([output_num],stddev=0.03))\n",
    "    std_hypothesis = tf.matmul(layer, W3) + B3\n",
    "\n",
    "    if reshape == True:\n",
    "        std_hypothesis = tf.reshape(std_hypothesis, [-1])\n",
    "    if use_relu == True:\n",
    "        fc_relu = tf.nn.relu(std_hypothesis)\n",
    "        return fc_relu\n",
    "    else:\n",
    "        return std_hypothesis\n",
    "    \n",
    "conv_layer1 = conv_layer1_fn(x, 1, 32)\n",
    "conv_layer2 = conv_layer2_fn(conv_layer1, 32, 64)\n",
    "flat = flat_layer(conv_layer2)\n",
    "fc_relu1 = fc_relu(flat, use_relu=True, output_num=batch_size, reshape=False)\n",
    "fc_relu2 = fc_relu(fc_relu1, use_relu=False, output_num=1, reshape=True)\n",
    "    \n",
    "## ------------------------------\n",
    "## OPTIMIZATION SESSION\n",
    "## Adapted from:\n",
    "## https://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/\n",
    "## ------------------------------\n",
    "    \n",
    "prediction_per_class = tf.nn.softmax(fc_relu2) #y_pred\n",
    "predicted_class = tf.argmax(prediction_per_class, axis=0)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=fc_relu2,labels=l)\n",
    "cost = tf.reduce_mean(cross_entropy)   \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "correct_prediction = tf.equal(predicted_class, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def show_progress(epoch, feed_dict_train, feed_dict_validate, val_loss):\n",
    "    tr_acc = sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "    val_acc = sess.run(accuracy, feed_dict=feed_dict_validate)\n",
    "    msg = \"Training Epoch {0} --- Training Accuracy: {1:>6.1%}, Validation Accuracy: {2:>6.1%},  Validation Loss: {3:.3f}\"\n",
    "    print(msg.format(epoch + 1, tr_acc, val_acc, val_loss))\n",
    "\n",
    "\n",
    "## ------------------------------\n",
    "## CATALYZING PROCESS\n",
    "## ------------------------------\n",
    "f_train, l_train = train_input_fn()\n",
    "f_val, l_val = val_input_fn()\n",
    "batch_counter = 0\n",
    "epoch_counter = 0\n",
    "epochs = train_num_examples/(val_num_examples/batch_size)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Run training batches\n",
    "print(\"PROCESSING...\")\n",
    "while f_train != None or l_train != None:\n",
    "    try:\n",
    "        x_train_batch, label_train_batch = sess.run([f_train['image'], l_train])\n",
    "        fd_train = {x: x_train_batch, l: label_train_batch}\n",
    "        sess.run(optimizer, feed_dict=fd_train)\n",
    "        batch_counter = batch_counter+1\n",
    "\n",
    "        if batch_counter % epochs == 0: \n",
    "            x_valid_batch, label_valid_batch = sess.run([f_val['image'], l_val]) \n",
    "            fd_val ={x: x_valid_batch, l: label_valid_batch}\n",
    "            val_loss = sess.run(cost, feed_dict=fd_val) \n",
    "            show_progress(epoch_counter, fd_train, fd_val, val_loss)\n",
    "            epoch_counter = epoch_counter+1\n",
    "            saver.save(sess, '/Volumes/imvDrive/cfdb-django/labasi_cnn')\n",
    "    except OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "saver = tf.train.import_meta_graph('/Volumes/imvDrive/cfdb-django/labasi_cnn.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "\n",
    "test_counter = 0\n",
    "f_test, l_test = test_input_fn()\n",
    "\n",
    "while f_test != None or l_test != None:\n",
    "    try:\n",
    "        x_test_batch, label_test_batch = sess.run([f_test['image'], l_test])\n",
    "        feed_dict_testing = {x: x_test_batch, l: label_test_batch}\n",
    "        result=sess.run(prediction_per_class, feed_dict=feed_dict_testing)\n",
    "        print(\"Epoch \"+str(test_counter*100)+\"%\"+\" / \"+str(result[0]))\n",
    "        test_counter = test_counter+1\n",
    "    except OutOfRangeError:\n",
    "        print(\"Ending...\")\n",
    "        pass\n",
    "print(\"FINISHED\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
